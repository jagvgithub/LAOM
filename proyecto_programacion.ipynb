{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPL7me/lhXnhmbkUp6scDYE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagvgithub/LAOM/blob/main/proyecto_programacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rsyq0TRkbGlC",
        "outputId": "178bd00c-eb61-4038-c541-1e95b617c598",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi"
      ],
      "metadata": {
        "id": "iN3vflxgavpH",
        "outputId": "270b2cd7-d76a-4371-b6b2-45e830b78265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.10/dist-packages/keras/api/preprocessing/image/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a5c665300c28>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkaggle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaggle_api_extended\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.10/dist-packages/keras/api/preprocessing/image/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01l4zi0UZg1X"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Conectar a la API de Kaggle\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Descargar el dataset\n",
        "dataset_name = 'misrakahmed/vegetable-image-dataset'\n",
        "api.dataset_download_files(dataset_name, path='.', unzip=True)\n",
        "\n",
        "# Ruta al conjunto de datos\n",
        "dataset_path = \"./vegetable-image-dataset\"  # Cambia esto si es necesario\n",
        "\n",
        "# Cargar las imágenes desde el directorio\n",
        "image_files = os.listdir(dataset_path)\n",
        "\n",
        "# Crear un DataFrame con las imágenes y sus etiquetas\n",
        "data = {'filename': image_files}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Supongamos que tienes una columna 'label' que define la clase de cada imagen\n",
        "# Asegúrate de ajustar esto según el formato de tus archivos\n",
        "df['label'] = df['filename'].apply(lambda x: x.split('_')[0])  # Cambia según el formato de tus archivos\n",
        "\n",
        "# Seleccionar una muestra de 100 registros\n",
        "sample_df = df.sample(n=100, random_state=42)\n",
        "\n",
        "# Parámetros\n",
        "input_shape = (150, 150, 3)  # Tamaño de las imágenes\n",
        "num_classes = len(sample_df['label'].unique())\n",
        "\n",
        "# Crear modelo\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Generador de datos\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    sample_df,\n",
        "    directory=dataset_path,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_dataframe(\n",
        "    sample_df,\n",
        "    directory=dataset_path,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Entrenamiento\n",
        "history = model.fit(train_generator, validation_data=validation_generator, epochs=20)\n",
        "\n",
        "# Gráfico de precisión\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.title('Precisión del modelo')\n",
        "plt.ylabel('Precisión')\n",
        "plt.xlabel('Épocas')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluar el modelo\n",
        "test_loss, test_acc = model.evaluate(validation_generator)\n",
        "print(\"Pérdida en validación:\", test_loss)\n",
        "print(\"Precisión en validación:\", test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Q8kWOTbgbnV2",
        "outputId": "d851b7bd-c301-477d-e21d-15b8fd322fea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las librerías necesarias\n",
        "\n",
        "\n",
        "username=\"josegomez123\",key=\"5f0644c841f13ce5ab7e9281f472a6a8\"\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Fz9lx7XAbygi",
        "outputId": "e88aa9d6-466c-4f66-af76-ae3c7be94d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0214771ce465>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkaggle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaggle_api_extended\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mApiClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\u001b[0m in \u001b[0;36mauthenticate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 raise IOError('Could not find {}. Make sure it\\'s located in'\n\u001b[0m\u001b[1;32m    408\u001b[0m                               \u001b[0;34m' {}. Or use the environment method. See setup'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                               \u001b[0;34m' instructions at'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura las credenciales\n",
        "\n",
        "username=\"josegomez123\"\n",
        "key=\"5f0644c841f13ce5ab7e9281f472a6a8\"\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = username\n",
        "os.environ['KAGGLE_KEY'] = key\n",
        "\n",
        "# Conectar a la API de Kaggle\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Ahora puedes descargar el dataset\n",
        "dataset_name = 'misrakahmed/vegetable-image-dataset'\n",
        "api.dataset_download_files(dataset_name, path='.', unzip=True)\n",
        "\n",
        "print(\"Dataset descargado exitosamente.\")"
      ],
      "metadata": {
        "id": "irLe3ftGgspD",
        "outputId": "b257019d-0739-476b-8d26-97ad412e693b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'KaggleApi' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-74102bed72f8>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Conectar a la API de Kaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'KaggleApi' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "# Define tus credenciales\n",
        "username = \"josegomez123\"  # Reemplaza con tu nombre de usuario\n",
        "key = \"5f0644c841f13ce5ab7e9281f472a6a8\"  # Reemplaza con tu clave\n",
        "\n",
        "# Configura las credenciales\n",
        "os.environ['KAGGLE_USERNAME'] = username\n",
        "os.environ['KAGGLE_KEY'] = key\n",
        "\n",
        "# Conectar a la API de Kaggle\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Ahora puedes descargar el dataset\n",
        "dataset_name = 'misrakahmed/vegetable-image-dataset'\n",
        "api.dataset_download_files(dataset_name, path='.', unzip=True)\n",
        "\n",
        "print(\"Dataset descargado exitosamente.\")\n"
      ],
      "metadata": {
        "id": "yz8a7VA1g_7F",
        "outputId": "0c2b3b19-59e1-401b-866c-a583dffa2ee9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset\n",
            "Dataset descargado exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0TAr4wF6hYCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Listar archivos en el directorio del dataset\n",
        "dataset_path = \"./vegetable-image-dataset\"  # Ajusta si es necesario\n",
        "image_files = os.listdir(dataset_path)\n",
        "\n",
        "# Mostrar las primeras 10 imágenes y sus etiquetas\n",
        "sample_images = image_files[:10]\n",
        "print(\"Primeras 10 imágenes:\", sample_images)"
      ],
      "metadata": {
        "id": "aZaNR9cYhQMm",
        "outputId": "cbf8d5a1-590f-44ac-f54f-42e6ae66a885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './vegetable-image-dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4b38bd5d1fd2>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Listar archivos en el directorio del dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./vegetable-image-dataset\"\u001b[0m  \u001b[0;31m# Ajusta si es necesario\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Mostrar las primeras 10 imágenes y sus etiquetas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './vegetable-image-dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "# Define tus credenciales\n",
        "username = \"josegomez123\"  # Reemplaza con tu nombre de usuario\n",
        "key = \"5f0644c841f13ce5ab7e9281f472a6a8\"  # Reemplaza con tu clave\n",
        "\n",
        "# Configura las credenciales\n",
        "os.environ['KAGGLE_USERNAME'] = username\n",
        "os.environ['KAGGLE_KEY'] = key\n",
        "\n",
        "# Conectar a la API de Kaggle\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Descargar el dataset\n",
        "dataset_name = 'misrakahmed/vegetable-image-dataset'\n",
        "api.dataset_download_files(dataset_name, path='.', unzip=True)\n",
        "\n",
        "print(\"Dataset descargado exitosamente.\")\n",
        "\n",
        "# Ruta al conjunto de datos\n",
        "dataset_path = \"./vegetable-image-dataset\"  # Ajusta según sea necesario\n",
        "\n",
        "# Cargar las imágenes desde el directorio\n",
        "image_files = os.listdir(dataset_path)\n",
        "\n",
        "# Crear un DataFrame con las imágenes y sus etiquetas\n",
        "data = {'filename': image_files}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Asumir que la etiqueta está en el nombre del archivo, ajusta según sea necesario\n",
        "df['label'] = df['filename'].apply(lambda x: x.split('_')[0])  # Cambia según el formato de tus archivos\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "qSW9xGv5hh6w",
        "outputId": "db217cdf-81ca-496e-f3bd-9195e794cc53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset\n",
            "Dataset descargado exitosamente.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './vegetable-image-dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-abab2a00a555>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Cargar las imágenes desde el directorio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Crear un DataFrame con las imágenes y sus etiquetas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './vegetable-image-dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "from zipfile import ZipFile\n",
        "import io\n",
        "import requests\n",
        "\n",
        "# Define tus credenciales\n",
        "username = \"josegomez123\"  # Reemplaza con tu nombre de usuario\n",
        "key = \"5f0644c841f13ce5ab7e9281f472a6a8\"  # Reemplaza con tu clave\n",
        "\n",
        "# Configura las credenciales\n",
        "os.environ['KAGGLE_USERNAME'] = username\n",
        "os.environ['KAGGLE_KEY'] = key\n",
        "\n",
        "# Conectar a la API de Kaggle\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Descargar el dataset como un archivo zip en memoria\n",
        "dataset_name = 'misrakahmed/vegetable-image-dataset'\n",
        "url = f\"https://www.kaggle.com/api/v1/datasets/download/{dataset_name.replace('/', '-')}\"\n",
        "response = requests.get(url, headers={\"Authorization\": f\"Bearer {key}\"})\n",
        "\n",
        "# Extraer el contenido del zip en memoria\n",
        "with ZipFile(io.BytesIO(response.content)) as z:\n",
        "    # Listar los archivos en el zip\n",
        "    file_list = z.namelist()\n",
        "\n",
        "    # Crear un DataFrame para guardar los nombres de los archivos y sus etiquetas\n",
        "    data = {'filename': [], 'label': []}\n",
        "\n",
        "    for file_name in file_list:\n",
        "        # Aquí asumimos que la etiqueta está en el nombre del archivo\n",
        "        label = file_name.split('_')[0]  # Ajusta según el formato de tus archivos\n",
        "        data['filename'].append(file_name)\n",
        "        data['label'].append(label)\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "NuWXXkFMiEg0",
        "outputId": "23ff3c37-34e0-4c42-e994-0771d8df4e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "File is not a zip file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-13354fa82150>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Extraer el contenido del zip en memoria\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Listar los archivos en el zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1337\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "# Define tus credenciales\n",
        "username = \"josegomez123\"  # Reemplaza con tu nombre de usuario\n",
        "key = \"5f0644c841f13ce5ab7e9281f472a6a8\"  # Reemplaza con tu clave\n",
        "\n",
        "# Configura las credenciales\n",
        "os.environ['KAGGLE_USERNAME'] = username\n",
        "os.environ['KAGGLE_KEY'] = key\n",
        "\n",
        "# Conectar a la API de Kaggle\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Descargar el dataset\n",
        "dataset_name = 'misrakahmed/vegetable-image-dataset'\n",
        "api.dataset_download_files(dataset_name, path='./', unzip=True)\n",
        "\n",
        "# Listar archivos en el directorio donde se descomprimió el dataset\n",
        "dataset_path = './vegetable-image-dataset'  # Ajusta si es necesario\n",
        "image_files = os.listdir(dataset_path)\n",
        "\n",
        "# Crear un DataFrame con las imágenes y sus etiquetas\n",
        "data = {'filename': image_files}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Asumir que la etiqueta está en el nombre del archivo, ajusta según sea necesario\n",
        "df['label'] = df['filename'].apply(lambda x: x.split('_')[0])  # Cambia según el formato de tus archivos\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "YMlBybc0iTnq",
        "outputId": "a1c7dcbe-2232-4213-8bae-4c0749c9b091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './vegetable-image-dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-61cc6168e7cc>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Listar archivos en el directorio donde se descomprimió el dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./vegetable-image-dataset'\u001b[0m  \u001b[0;31m# Ajusta si es necesario\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Crear un DataFrame con las imágenes y sus etiquetas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './vegetable-image-dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Ruta al archivo ZIP\n",
        "zip_file_path = r\"C:\\Users\\jose\\Downloads\\archive.zip\"  # Asegúrate de que la extensión sea correcta\n",
        "\n",
        "# Descomprimir el archivo ZIP\n",
        "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(r\"C:\\Users\\jose\\Downloads\\vegetable-image-dataset\")  # Cambia a la ruta que prefieras\n",
        "\n",
        "# Ruta del conjunto de datos descomprimido\n",
        "dataset_path = r\"C:\\Users\\jose\\Downloads\\vegetable-image-dataset\"\n",
        "\n",
        "# Cargar las imágenes desde el directorio\n",
        "image_files = os.listdir(dataset_path)\n",
        "\n",
        "# Crear un DataFrame con las imágenes y sus etiquetas\n",
        "data = {'filename': image_files}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Asumir que la etiqueta está en el nombre del archivo, ajusta según sea necesario\n",
        "df['label'] = df['filename'].apply(lambda x: x.split('_')[0])  # Cambia según el formato de tus archivos\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "45YB3Yb9kJuJ",
        "outputId": "d86b04b3-10c4-45db-f1c3-edd9a7511802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\jose\\\\Downloads\\\\archive.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6333d4362e8e>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Descomprimir el archivo ZIP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"C:\\Users\\jose\\Downloads\\vegetable-image-dataset\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Cambia a la ruta que prefieras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\jose\\\\Downloads\\\\archive.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Ruta a la carpeta que contiene los conjuntos de datos\n",
        "base_path = r\"C:\\Users\\jose\\Downloads\\archive\\Vegetable Images\"\n",
        "\n",
        "# Inicializar diccionarios para almacenar DataFrames\n",
        "dataframes = {}\n",
        "\n",
        "# Listar conjuntos de datos\n",
        "for set_type in ['train', 'test', 'validation']:\n",
        "    set_path = os.path.join(base_path, set_type)\n",
        "    # Inicializar listas para almacenar los datos\n",
        "    image_files = []\n",
        "    labels = []\n",
        "\n",
        "    # Recorrer las carpetas de categorías\n",
        "    for category in os.listdir(set_path):\n",
        "        category_path = os.path.join(set_path, category)\n",
        "\n",
        "        # Asegurarse de que sea una carpeta\n",
        "        if os.path.isdir(category_path):\n",
        "            for filename in os.listdir(category_path):\n",
        "                # Obtener la ruta completa de la imagen\n",
        "                image_files.append(os.path.join(category, filename))\n",
        "                labels.append(category)  # Usar el nombre de la carpeta como etiqueta\n",
        "\n",
        "    # Crear un DataFrame para el conjunto actual\n",
        "    df = pd.DataFrame({'filename': image_files, 'label': labels})\n",
        "    dataframes[set_type] = df  # Guardar el DataFrame en el diccionario\n",
        "\n",
        "    # Mostrar las primeras filas del DataFrame\n",
        "    print(f\"DataFrame para {set_type}:\")\n",
        "    print(df.head(), \"\\n\")\n",
        "\n",
        "# Acceder a los DataFrames\n",
        "train_df = dataframes['train']\n",
        "test_df = dataframes['test']\n",
        "validation_df = dataframes['validation']\n"
      ],
      "metadata": {
        "id": "siPRnd5eoPE_",
        "outputId": "e7c95926-97c0-4d90-ecd1-0e91f4bfb56a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\jose\\\\Downloads\\\\archive\\\\Vegetable Images/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d787b2da5aeb>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Recorrer las carpetas de categorías\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mcategory_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\jose\\\\Downloads\\\\archive\\\\Vegetable Images/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nueva sección"
      ],
      "metadata": {
        "id": "KZEI06njtA8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Definir la ruta base\n",
        "base_path = '/content/Vegetable Images'\n",
        "\n",
        "# Inicializar diccionarios para almacenar DataFrames\n",
        "dataframes = {}\n",
        "\n",
        "# Listar conjuntos de datos\n",
        "for set_type in ['train', 'test', 'validation']:\n",
        "    set_path = os.path.join(base_path, set_type)\n",
        "\n",
        "    # Verificar si la ruta existe\n",
        "    if not os.path.exists(set_path):\n",
        "        print(f\"Ruta no encontrada: {set_path}\")\n",
        "        continue\n",
        "\n",
        "    # Inicializar listas para almacenar los datos\n",
        "    image_files = []\n",
        "    labels = []\n",
        "\n",
        "    # Recorrer las carpetas de categorías\n",
        "    for category in os.listdir(set_path):\n",
        "        category_path = os.path.join(set_path, category)\n",
        "\n",
        "        # Asegurarse de que sea una carpeta\n",
        "        if os.path.isdir(category_path):\n",
        "            for filename in os.listdir(category_path):\n",
        "                image_files.append(os.path.join(category, filename))\n",
        "                labels.append(category)  # Usar el nombre de la carpeta como etiqueta\n",
        "\n",
        "    # Crear un DataFrame para el conjunto actual\n",
        "    df = pd.DataFrame({'filename': image_files, 'label': labels})\n",
        "    dataframes[set_type] = df  # Guardar el DataFrame en el diccionario\n",
        "\n",
        "    # Mostrar las primeras filas del DataFrame\n",
        "    print(f\"DataFrame para {set_type}:\")\n",
        "    print(df.head(), \"\\n\")\n",
        "\n",
        "# Acceder a los DataFrames\n",
        "train_df = dataframes.get('train', pd.DataFrame())\n",
        "test_df = dataframes.get('test', pd.DataFrame())\n",
        "validation_df = dataframes.get('validation', pd.DataFrame())\n",
        "\n",
        "# Comprobar el tamaño de los DataFrames\n",
        "print(f\"Tamaño del DataFrame de entrenamiento: {train_df.shape}\")\n",
        "print(f\"Tamaño del DataFrame de prueba: {test_df.shape}\")\n",
        "print(f\"Tamaño del DataFrame de validación: {validation_df.shape}\")\n"
      ],
      "metadata": {
        "id": "xC2gXJDZtn-c",
        "outputId": "e4463713-b8dc-4ade-9a2b-c04c92745b40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame para train:\n",
            "          filename   label\n",
            "0  Carrot/0034.jpg  Carrot\n",
            "1  Carrot/0521.jpg  Carrot\n",
            "2  Carrot/0082.jpg  Carrot\n",
            "3  Carrot/0910.jpg  Carrot\n",
            "4  Carrot/0943.jpg  Carrot \n",
            "\n",
            "DataFrame para test:\n",
            "          filename   label\n",
            "0  Carrot/1198.jpg  Carrot\n",
            "1  Carrot/1136.jpg  Carrot\n",
            "2  Carrot/1025.jpg  Carrot\n",
            "3  Carrot/1091.jpg  Carrot\n",
            "4  Carrot/1056.jpg  Carrot \n",
            "\n",
            "DataFrame para validation:\n",
            "          filename   label\n",
            "0  Carrot/1340.jpg  Carrot\n",
            "1  Carrot/1262.jpg  Carrot\n",
            "2  Carrot/1218.jpg  Carrot\n",
            "3  Carrot/1229.jpg  Carrot\n",
            "4  Carrot/1213.jpg  Carrot \n",
            "\n",
            "Tamaño del DataFrame de entrenamiento: (15000, 2)\n",
            "Tamaño del DataFrame de prueba: (3000, 2)\n",
            "Tamaño del DataFrame de validación: (3000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspeccionar los DataFrames\n",
        "for set_type, df in dataframes.items():\n",
        "    print(f\"DataFrame para {set_type}:\")\n",
        "    print(df.head())  # Mostrar las primeras filas\n",
        "    print(f\"Tamaño: {df.shape}\\n\")  # Mostrar el tamaño\n",
        "\n"
      ],
      "metadata": {
        "id": "0Nb0wkiNxopS",
        "outputId": "ef97cd1f-fc14-4cb3-9348-9d64b5c13acb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame para train:\n",
            "          filename   label\n",
            "0  Carrot/0034.jpg  Carrot\n",
            "1  Carrot/0521.jpg  Carrot\n",
            "2  Carrot/0082.jpg  Carrot\n",
            "3  Carrot/0910.jpg  Carrot\n",
            "4  Carrot/0943.jpg  Carrot\n",
            "Tamaño: (15000, 2)\n",
            "\n",
            "DataFrame para test:\n",
            "          filename   label\n",
            "0  Carrot/1198.jpg  Carrot\n",
            "1  Carrot/1136.jpg  Carrot\n",
            "2  Carrot/1025.jpg  Carrot\n",
            "3  Carrot/1091.jpg  Carrot\n",
            "4  Carrot/1056.jpg  Carrot\n",
            "Tamaño: (3000, 2)\n",
            "\n",
            "DataFrame para validation:\n",
            "          filename   label\n",
            "0  Carrot/1340.jpg  Carrot\n",
            "1  Carrot/1262.jpg  Carrot\n",
            "2  Carrot/1218.jpg  Carrot\n",
            "3  Carrot/1229.jpg  Carrot\n",
            "4  Carrot/1213.jpg  Carrot\n",
            "Tamaño: (3000, 2)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Definir parámetros de augmentación para el conjunto de entrenamiento\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Definir solo normalización para los conjuntos de prueba y validación\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generar datos para el conjunto de entrenamiento\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory='/content/Vegetable Images/train',  # Cambiar esto si es necesario\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Generar datos para el conjunto de validación\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=validation_df,\n",
        "    directory='/content/Vegetable Images/validation',  # Cambiar esto si es necesario\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Generar datos para el conjunto de test\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory='/content/Vegetable Images/test',  # Cambiar esto si es necesario\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "id": "gcW1h6QSz0K2",
        "outputId": "91b35fe8-da39-4830-9894-bcf1bac712e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15000 validated image filenames belonging to 15 classes.\n",
            "Found 3000 validated image filenames belonging to 15 classes.\n",
            "Found 3000 validated image filenames belonging to 15 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Definir el modelo\n",
        "from tensorflow.keras import models, layers\n",
        "\n",
        "# Definición del modelo secuencial\n",
        "model = models.Sequential([\n",
        "\n",
        "    # Primera capa convolucional: 32 filtros de 3x3, activación ReLU, entrada de 150x150x3\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "\n",
        "    # Capa de max pooling: reduce la dimensión de la salida anterior\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Segunda capa convolucional: 64 filtros de 3x3, activación ReLU\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "    # Otra capa de max pooling\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Tercera capa convolucional: 128 filtros de 3x3, activación ReLU\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "\n",
        "    # Otra capa de max pooling\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Aplanar la salida 2D a un vector unidimensional\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # Capa densa con 128 neuronas y activación ReLU\n",
        "    layers.Dense(128, activation='relu'),\n",
        "\n",
        "    # Capa de dropout: desactiva el 50% de las neuronas para prevenir sobreajuste\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    # Capa de salida: neuronas igual al número de clases, activación softmax\n",
        "    layers.Dense(len(train_df['label'].unique()), activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "9ly9WV5yz9Ib",
        "outputId": "7949a124-e070-4369-9274-12d622f691dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "K_xpOmeb8He0",
        "outputId": "7040d96e-04dc-426a-b40d-8feb6e4065fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36992\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m4,735,104\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │           \u001b[38;5;34m1,935\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36992</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,735,104</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,935</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,830,287\u001b[0m (18.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,830,287</span> (18.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,830,287\u001b[0m (18.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,830,287</span> (18.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "# Entrenamiento\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator),\n",
        "    epochs=2,\n",
        "    verbose=1  # Cambiar a 1 para imprimir los resultados por cada época\n",
        ")\n"
      ],
      "metadata": {
        "id": "n61dvfrB0Gej",
        "outputId": "8f874366-79ab-4397-f75f-b40c17ee297d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m 15/469\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:18\u001b[0m 2s/step - accuracy: 0.5312 - loss: 1.3814"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Graficar la precisión\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)  # 1 fila, 2 columnas, 1ª gráfica\n",
        "plt.plot(history.history['accuracy'], label='Precisión de Entrenamiento')\n",
        "plt.plot(history.history['val_accuracy'], label='Precisión de Validación')\n",
        "plt.title('Precisión del Modelo')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.legend()\n",
        "\n",
        "# Graficar la pérdida\n",
        "plt.subplot(1, 2, 2)  # 1 fila, 2 columnas, 2ª gráfica\n",
        "plt.plot(history.history['loss'], label='Pérdida de Entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Pérdida de Validación')\n",
        "plt.title('Pérdida del Modelo')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6zxtZGU43Uaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "bl79j1rU0d_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo\n",
        "model.save('modelo_planta.h5')  # Cambia el nombre del archivo según sea necesario\n",
        "print(\"Modelo guardado exitosamente.\")"
      ],
      "metadata": {
        "id": "cvg_FRjE1PbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Cargar el modelo\n",
        "loaded_model = load_model('modelo_planta.h5')\n",
        "print(\"Modelo cargado exitosamente.\")"
      ],
      "metadata": {
        "id": "HMFR75Mc1W6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator),\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "# Guardar el modelo\n",
        "model.save('modelo_planta.h5')\n",
        "print(\"Modelo guardado exitosamente.\")\n",
        "\n",
        "# Evaluar el modelo\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {test_accuracy:.2f}')\n",
        "\n",
        "# Cargar el modelo posteriormente (si es necesario)\n",
        "loaded_model = load_model('modelo_planta.h5')\n",
        "print(\"Modelo cargado exitosamente.\")\n"
      ],
      "metadata": {
        "id": "p6VQQ14y1jxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LIGEla2_z05c"
      }
    }
  ]
}